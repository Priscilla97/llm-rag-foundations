{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priscilla97/llm-rag-foundations/blob/main/02_fine_tuning/2_Fine_tuning_a_model_with_the_Trainer_API_or_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JOXLMtXZrLA"
      },
      "source": [
        "# Fine-tuning a model with the Trainer API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0d-n6zJZrLL"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDP6Mq2kZrLN"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation\n",
        "The code examples below assume you have already executed the examples in the previous section. Here is a short summary recapping what you need:"
      ],
      "metadata": {
        "id": "J5Qc9-Cshvfp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSyi-AFQZrLS"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
        "\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "1) define a **TrainingArguments** class that will contain all the *hyperparameters* the Trainer will use for training and evaluation.\n",
        "\n",
        "The only argument you have to provide is a **directory** where the trained model will be **saved**.\n",
        "\n",
        "Advanced Configuration: https://huggingface.co/learn/cookbook/en/fine_tuning_code_llm_on_single_gpu\n",
        "\n",
        "If you want to automatically upload your model to the Hub during training, pass along **push_to_hub=True** in the TrainingArguments.\n",
        "\n"
      ],
      "metadata": {
        "id": "4vTNM361h90J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r7MZHyeZrLV"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\"test-trainer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) define our model.\n",
        "\n",
        "As in the previous chapter, we will use the **AutoModelForSequenceClassification** class, with two labels:"
      ],
      "metadata": {
        "id": "xnKV8OwhiTVR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGe0BwgPZrLX"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You get a **warning** after instantiating this pretrained model.\n",
        "\n",
        "- This is because BERT has not been pretrained on classifying pairs of sentences\n",
        "\n",
        "- so the **head of the pretrained model has been discarded** and\n",
        "\n",
        "- a **new head** suitable for sequence classification has been added instead.\n",
        "\n",
        "The warnings indicate that:\n",
        "- some **weights were not used** (the ones corresponding to the dropped pretraining head)\n",
        "\n",
        "- and that some others were **randomly initialized** (the ones for the new head).\n",
        "\n",
        "\n",
        "3) define a **Trainer** by passing it all the objects constructed up to now\n",
        "- the model,\n",
        "- the training_args,\n",
        "- the training and validation datasets,\n",
        "- our data_collator,\n",
        "- our processing_class.\n",
        "\n",
        "The **processing_class** parameter is a newer addition that *tells the Trainer which tokenizer to use for processing*.\n",
        "\n",
        "The default **data_collator** used by the Trainer will be a DataCollatorWithPadding.\n"
      ],
      "metadata": {
        "id": "9heMUrs6jYN2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "horEJUCwZrLZ"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    processing_class=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fine-tune the model on our dataset, we just have to call the train() method of our Trainer:"
      ],
      "metadata": {
        "id": "mri6khixkraL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cf_DT5OZrLc"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will start the **fine-tuning** (in GPU) and report the *training loss* every 500 steps.\n",
        "\n",
        "It won’t, however, tell you how well (or badly) your model is performing. To do so we need:\n",
        "\n",
        "- to tell the Trainer to **evaluate** during training by setting **eval_strategy** in TrainingArguments\n",
        "\n",
        "- how many **\"steps\"** (evaluate every **eval_steps**) or\n",
        "\n",
        "- **\"epoch\"** (evaluate at the end of each epoch).\n",
        "\n",
        "- **compute_metrics**() function to calculate a metric during said evaluation (otherwise the evaluation would just have printed the loss, which is not a very intuitive number)."
      ],
      "metadata": {
        "id": "JUoiCqHikuUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "Let’s see how we can build a useful **compute_metrics**() function and use it the next time we train.\n",
        "\n",
        "The function must take an **EvalPrediction object**, a named tuple:\n",
        "- predictions field (dataset validation)\n",
        "- label_ids field\n",
        "\n",
        "and will return a **dictionary** mapping strings (names metrics) to floats (values).\n",
        "\n",
        "To get some predictions from our model, we can use the **Trainer.predict(**) command:"
      ],
      "metadata": {
        "id": "2DXzLFeTmGM-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dfX13GNZrLe",
        "outputId": "aaf4ba0e-41bd-44e0-cb30-9152378196e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(408, 2) (408,)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the predict() method is another named tuple with three fields: **predictions, label_ids, and metrics**.\n",
        "\n",
        "The **metrics field** will just contain the **loss** on the dataset passed, as well as some time metrics.\n",
        "\n",
        "As you can see, predictions is a **two-dimensional array** with shape 408 x 2 (408 being the number of elements in the dataset we used). <br>Those are the **logits** for each element of the dataset we passed to predict().\n",
        "\n",
        "To transform them into predictions that we can compare to our labels, we need to take the index with the maximum value on the second axis:"
      ],
      "metadata": {
        "id": "p0Goo5N8ejd9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdvXb541ZrLi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "preds = np.argmax(predictions.predictions, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now compare those preds to the labels.\n",
        "\n",
        "We can load the metrics associated with the MRPC dataset as easily as we loaded the dataset, this time with the **evaluate.load() function.**\n",
        "\n",
        "The object returned has a **compute()** method we can use to do the metric calculation:"
      ],
      "metadata": {
        "id": "GCMJa3LAfWzT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHEe3qAfZrLj",
        "outputId": "063d6291-2cba-49c3-a4ac-0161d46ebd54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "metric.compute(predictions=preds, references=predictions.label_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random initialization of the model head might change the metrics it achieved.**\n",
        "\n",
        "Here, we can see our model has an **accuracy** of 85.78% on the validation set and an **F1 score** of 89.97.\n",
        "\n",
        "Wrapping everything together, we get our compute_metrics() function:"
      ],
      "metadata": {
        "id": "j9voDAHWfxrS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJXEeJCKZrLk"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And to see it used in action to report metrics at the end of each epoch, here is how we define a new Trainer with this compute_metrics() function:"
      ],
      "metadata": {
        "id": "3Gon9GcNgTj9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvzCVmjyZrLm"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we create a new TrainingArguments with its eval_strategy set to \"epoch\" and a new model — otherwise, we would just be continuing the training of the model we have already trained. To launch a new training run, we execute:"
      ],
      "metadata": {
        "id": "phiqCObsgbRY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eh1ASHCYZrLn"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Training Features\n",
        "\n",
        "The Trainer comes with many built-in features that make modern deep learning best practices accessible:\n",
        "\n",
        "### Mixed Precision Training:\n",
        "Use fp16=True in your training arguments for faster training and reduced memory usage:"
      ],
      "metadata": {
        "id": "fe_BhU7agzPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    \"test-trainer\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    fp16=True,  # Enable mixed precision\n",
        ")"
      ],
      "metadata": {
        "id": "v3fFqPW7g58-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Accumulation:\n",
        "For effective larger batch sizes when GPU memory is limited:"
      ],
      "metadata": {
        "id": "vSXvPtnXg9I-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    \"test-trainer\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,  # Effective batch size = 4 * 4 = 16\n",
        ")"
      ],
      "metadata": {
        "id": "-HznNcLKhAVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning Rate Scheduling:\n",
        "The Trainer uses linear decay by default, but you can customize this:"
      ],
      "metadata": {
        "id": "QAXbvQ_ZhECh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    \"test-trainer\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    lr_scheduler_type=\"cosine\",  # Try different schedulers\n",
        ")"
      ],
      "metadata": {
        "id": "C3We1kolhHps"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Fine-tuning a model with the Trainer API or Keras",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}